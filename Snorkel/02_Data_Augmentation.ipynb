{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Make sure we're running from the spam/ directory\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"spam\")\n",
    "\n",
    "# Turn off TensorFlow logging messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# For reproducibility\n",
    "seed = 0\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "DISPLAY_ALL_TEXT = False\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0 if DISPLAY_ALL_TEXT else 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tejakummarikuntla/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from utils import load_spam_dataset\n",
    "\n",
    "df_train, _, df_valid, df_test = load_spam_dataset(load_train_labels=True)\n",
    "\n",
    "# We pull out the label vectors for ease of use later\n",
    "Y_valid = df_valid[\"label\"].values\n",
    "Y_train = df_train[\"label\"].values\n",
    "Y_test = df_test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alessandro leite</td>\n",
       "      <td>2014-11-05T22:21:36</td>\n",
       "      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salim Tayara</td>\n",
       "      <td>2014-11-02T14:33:30</td>\n",
       "      <td>if your like drones, plz subscribe to Kamal Ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phuc Ly</td>\n",
       "      <td>2014-01-20T15:27:47</td>\n",
       "      <td>go here to check the views :3﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DropShotSk8r</td>\n",
       "      <td>2014-01-19T04:27:18</td>\n",
       "      <td>Came here to check the views, goodbye.﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>css403</td>\n",
       "      <td>2014-11-07T14:25:48</td>\n",
       "      <td>i am 2,126,492,636 viewer :D﻿</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                 date  \\\n",
       "0  Alessandro leite  2014-11-05T22:21:36   \n",
       "1      Salim Tayara  2014-11-02T14:33:30   \n",
       "2           Phuc Ly  2014-01-20T15:27:47   \n",
       "3      DropShotSk8r  2014-01-19T04:27:18   \n",
       "4            css403  2014-11-07T14:25:48   \n",
       "\n",
       "                                                text  label  video  \n",
       "0  pls http://www10.vakinha.com.br/VaquinhaE.aspx...      1      1  \n",
       "1  if your like drones, plz subscribe to Kamal Ta...      1      1  \n",
       "2                     go here to check the views :3﻿      0      1  \n",
       "3            Came here to check the views, goodbye.﻿      0      1  \n",
       "4                      i am 2,126,492,636 viewer :D﻿      0      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import names\n",
    "from snorkel.augmentation import transformation_function\n",
    "\n",
    "# Pregenerate some random person names to replace existing ones with\n",
    "# for the transformation strategies below\n",
    "replacement_names = [names.get_full_name() for _ in range(50)]\n",
    "\n",
    "\n",
    "# Replace a random named entity with a different entity of the same type.\n",
    "@transformation_function(pre=[spacy])\n",
    "def change_person(x):\n",
    "    person_names = [ent.text for ent in x.doc.ents if ent.label_ == \"PERSON\"]\n",
    "    # If there is at least one person name, replace a random one. Else return None.\n",
    "    if person_names:\n",
    "            name_to_replace = np.random.choice(person_names)\n",
    "            replacement_name = np.random.choice(replacement_names)\n",
    "            x.text = x.text.replace(name_to_replace, replacement_name)\n",
    "            return x\n",
    "\n",
    "\n",
    "# Swap two adjectives at random.\n",
    "@transformation_function(pre=[spacy])\n",
    "def swap_adjectives(x):\n",
    "    adjective_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"ADJ\"]\n",
    "    # Check that there are at least two adjectives to swap.\n",
    "    if len(adjective_idxs) >= 2:\n",
    "        idx1, idx2 = sorted(np.random.choice(adjective_idxs, 2, replace=False))\n",
    "        # Swap tokens in positions idx1 and idx2.\n",
    "        x.text = \" \".join(\n",
    "            [\n",
    "                x.doc[:idx1].text,\n",
    "                x.doc[idx2].text,\n",
    "                x.doc[1 + idx1 : idx2].text,\n",
    "                x.doc[idx1].text,\n",
    "                x.doc[1 + idx2 :].text,\n",
    "            ]\n",
    "        )\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/tejakummarikuntla/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "\n",
    "def get_synonym(word, pos=None):\n",
    "    \"\"\"Get synonym for word given its part-of-speech (pos).\"\"\"\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    # Return None if wordnet has no synsets (synonym sets) for this word and pos.\n",
    "    if synsets:\n",
    "        words = [lemma.name() for lemma in synsets[0].lemmas()]\n",
    "        if words[0].lower() != word.lower():  # Skip if synonym is same as word.\n",
    "            # Multi word synonyms in wordnet use '_' as a separator e.g. reckon_with. Replace it with space.\n",
    "            return words[0].replace(\"_\", \" \")\n",
    "\n",
    "\n",
    "def replace_token(spacy_doc, idx, replacement):\n",
    "    \"\"\"Replace token in position idx with replacement.\"\"\"\n",
    "    return \" \".join([spacy_doc[:idx].text, replacement, spacy_doc[1 + idx :].text])\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_verb_with_synonym(x):\n",
    "    # Get indices of verb tokens in sentence.\n",
    "    verb_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"VERB\"]\n",
    "    if verb_idxs:\n",
    "        # Pick random verb idx to replace.\n",
    "        idx = np.random.choice(verb_idxs)\n",
    "        synonym = get_synonym(x.doc[idx].text, pos=\"v\")\n",
    "        # If there's a valid verb synonym, replace it. Otherwise, return None.\n",
    "        if synonym:\n",
    "            x.text = replace_token(x.doc, idx, synonym)\n",
    "            return x\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_noun_with_synonym(x):\n",
    "    # Get indices of noun tokens in sentence.\n",
    "    noun_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"NOUN\"]\n",
    "    if noun_idxs:\n",
    "        # Pick random noun idx to replace.\n",
    "        idx = np.random.choice(noun_idxs)\n",
    "        synonym = get_synonym(x.doc[idx].text, pos=\"n\")\n",
    "        # If there's a valid noun synonym, replace it. Otherwise, return None.\n",
    "        if synonym:\n",
    "            x.text = replace_token(x.doc, idx, synonym)\n",
    "            return x\n",
    "\n",
    "\n",
    "@transformation_function(pre=[spacy])\n",
    "def replace_adjective_with_synonym(x):\n",
    "    # Get indices of adjective tokens in sentence.\n",
    "    adjective_idxs = [i for i, token in enumerate(x.doc) if token.pos_ == \"ADJ\"]\n",
    "    if adjective_idxs:\n",
    "        # Pick random adjective idx to replace.\n",
    "        idx = np.random.choice(adjective_idxs)\n",
    "        synonym = get_synonym(x.doc[idx].text, pos=\"a\")\n",
    "        # If there's a valid adjective synonym, replace it. Otherwise, return None.\n",
    "        if synonym:\n",
    "            x.text = replace_token(x.doc, idx, synonym)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = [\n",
    "    change_person,\n",
    "    swap_adjectives,\n",
    "    replace_verb_with_synonym,\n",
    "    replace_noun_with_synonym,\n",
    "    replace_adjective_with_synonym,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF Name</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Transformed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>change_person</td>\n",
       "      <td>\"eye of the tiger\" \"i am the champion\" seems l...</td>\n",
       "      <td>\"eye of the tiger\" \"i am the champion\" seems l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>swap_adjectives</td>\n",
       "      <td>hey guys look im aware im spamming and it piss...</td>\n",
       "      <td>hey guys look im aware im spamming and it piss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>replace_verb_with_synonym</td>\n",
       "      <td>\"eye of the tiger\" \"i am the champion\" seems l...</td>\n",
       "      <td>\"eye of the tiger\" \"i am the champion\" look li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>replace_noun_with_synonym</td>\n",
       "      <td>Hey, check out my new website!! This site is a...</td>\n",
       "      <td>Hey, check out my new website!! This site is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>replace_adjective_with_synonym</td>\n",
       "      <td>You gotta say its funny. well not 2 billion wo...</td>\n",
       "      <td>You gotta say its funny. well not 2 billion wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          TF Name  \\\n",
       "0                   change_person   \n",
       "1                 swap_adjectives   \n",
       "2       replace_verb_with_synonym   \n",
       "3       replace_noun_with_synonym   \n",
       "4  replace_adjective_with_synonym   \n",
       "\n",
       "                                       Original Text  \\\n",
       "0  \"eye of the tiger\" \"i am the champion\" seems l...   \n",
       "1  hey guys look im aware im spamming and it piss...   \n",
       "2  \"eye of the tiger\" \"i am the champion\" seems l...   \n",
       "3  Hey, check out my new website!! This site is a...   \n",
       "4  You gotta say its funny. well not 2 billion wo...   \n",
       "\n",
       "                                    Transformed Text  \n",
       "0  \"eye of the tiger\" \"i am the champion\" seems l...  \n",
       "1  hey guys look im aware im spamming and it piss...  \n",
       "2  \"eye of the tiger\" \"i am the champion\" look li...  \n",
       "3  Hey, check out my new website!! This site is a...  \n",
       "4  You gotta say its funny. well not 2 billion wo...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import preview_tfs\n",
    "\n",
    "preview_tfs(df_train, tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import RandomPolicy\n",
    "\n",
    "random_policy = RandomPolicy(\n",
    "    len(tfs), sequence_length=2, n_per_original=2, keep_original=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import MeanFieldPolicy\n",
    "\n",
    "mean_field_policy = MeanFieldPolicy(\n",
    "    len(tfs),\n",
    "    sequence_length=2,\n",
    "    n_per_original=2,\n",
    "    keep_original=True,\n",
    "    p=[0.05, 0.05, 0.3, 0.3, 0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:41<00:00, 37.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.augmentation import PandasTFApplier\n",
    "\n",
    "tf_applier = PandasTFApplier(tfs, mean_field_policy)\n",
    "df_train_augmented = tf_applier.apply(df_train)\n",
    "Y_train_augmented = df_train_augmented[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size: 1586\n",
      "Augmented training set size: 2405\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original training set size: {len(df_train)}\")\n",
    "print(f\"Augmented training set size: {len(df_train_augmented)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[Snorkel Tutorials](https://github.com/snorkel-team/snorkel-tutorials/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
